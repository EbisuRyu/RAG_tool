MODEL:
    TEMPERATURE: 0.2
    STREAM: True

    SERVICE: openai # [ ollama, openai, groq, gemini ]

    MODEL_ID: gpt-4o-mini

CONTEXTUAL_RAG:
    CHUNK_SIZE: 2048
    SERVICE: huggingface 
    MODEL: "https://huggingface.co/hienhayho/llama-3.2-1B-instruct-10max-steps/resolve/main/unsloth.Q8_0.gguf"

    ORIGIN_RAG_COLLECTION_NAME: "original_rag"
    CONTEXTUAL_RAG_COLLECTION_NAME: "contextual_rag"

    QDRANT_URL: "http://localhost:6333"

    ELASTIC_SEARCH_URL: "http://localhost:9200"
    ELASTIC_SEARCH_INDEX_NAME: "contextual_rag"

    NUM_CHUNKS_TO_RECALL: 150

    SEMANTIC_WEIGHT: 0.8
    BM25_WEIGHT: 0.2

    TOP_N: 3

AGENT:
    TYPE: "openai" # [openai, react]
